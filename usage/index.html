<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Usage - DEPy</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Usage";
        var mkdocs_page_input_path = "usage.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> DEPy
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Usage</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting started</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#example-workflow">Example workflow</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#loading-the-data">Loading the data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exploring-the-summarizedpy-object">Exploring the SummarizedPy object</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#subsetting-and-slicing">Subsetting and slicing</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#a-note-on-dimensionality">A note on dimensionality</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#filtering-by-sample-and-feature-metadata">Filtering by sample and feature metadata</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#missingness-filtering">Missingness filtering</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#highly-variable-feature-selection">Highly variable feature selection</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#transformations">Transformations</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#imputation">Imputation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#surrogate-variable-analysis">Surrogate variable analysis</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#why-use-sva">Why use sva</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#this-is-why-sva">This is why sva</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#limma-trend">limma-trend</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#a-brief-note-on-design-formulae">A brief note on design formulae</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#volcano-plots">Volcano plots</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#pca-plots">PCA plots</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../api/">API Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../HISTORY/">Changelog</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">DEPy</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Usage</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/SebastianDHA/DEPy/edit/master/docs/usage.md">Edit on SebastianDHA/DEPy</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="usage">Usage<a class="headerlink" href="#usage" title="Permanent link">&para;</a></h1>
<h2 id="getting-started">Getting started<a class="headerlink" href="#getting-started" title="Permanent link">&para;</a></h2>
<p>To use DEPy in a project, start the 'depy' conda environment:</p>
<p><div class="highlight"><pre><span></span><code>conda<span class="w"> </span>activate<span class="w"> </span>depy
</code></pre></div>
Then, open a script or a Jupyter Notebook and simply:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">depy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dp</span>
</code></pre></div></p>
<h2 id="example-workflow">Example workflow<a class="headerlink" href="#example-workflow" title="Permanent link">&para;</a></h2>
<h3 id="loading-the-data">Loading the data<a class="headerlink" href="#loading-the-data" title="Permanent link">&para;</a></h3>
<p>Let's load the example dataset that comes with DEPy (courtesy of the ImputeLCMD package).
This is a real-world proteomics <a href="https://proteomecentral.proteomexchange.org/cgi/GetDataset?ID=PXD000438">dataset</a>
of human cancer cell lines (3,709 features, 12 samples).
Data were processed with MaxQaunt and comes in the form of protein groups and their intensities.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">depy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dp</span>

<span class="n">sp</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">SummarizedPy</span><span class="p">()</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">load_example_data</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="exploring-the-summarizedpy-object">Exploring the SummarizedPy object<a class="headerlink" href="#exploring-the-summarizedpy-object" title="Permanent link">&para;</a></h3>
<p>Data are stored in three main attributes:
- data (numpy ndarray with float or int dtype)
- features (pandas DataFrame)
- samples (pandas DataFrame)</p>
<p>These can be readily accessed
<div class="highlight"><pre><span></span><code><span class="c1"># Check expression data</span>
<span class="n">sp</span><span class="o">.</span><span class="n">data</span>

<span class="c1"># Check feature metadata</span>
<span class="n">sp</span><span class="o">.</span><span class="n">features</span>

<span class="c1"># Check sample metadata</span>
<span class="n">sp</span><span class="o">.</span><span class="n">samples</span>
</code></pre></div>
To check current dimensions, we can simply invoke the object or call <code>print()</code> on it
<div class="highlight"><pre><span></span><code><span class="c1"># See current dimensions in &#39;repr&#39; format</span>
<span class="n">sp</span>

<span class="c1"># Get a user-friendly summary of the entire object</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sp</span><span class="p">)</span>
</code></pre></div>
The last statement will reveal another useful attribute, the <code>history</code> attribute.
<div class="highlight"><pre><span></span><code><span class="c1"># Check history attribute</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
This attribute keeps a faithful record of <em>everything</em> you do to the <code>SummarizedPy</code> object, including function calls and parameters.
This is incredibly handy for reproducibility.</p>
<h2 id="subsetting-and-slicing">Subsetting and slicing<a class="headerlink" href="#subsetting-and-slicing" title="Permanent link">&para;</a></h2>
<p><code>SummarizedPy</code> objects can be subset and sliced just like SummarizedExperiment in R.
The objects are indexed as <code>sp[features, samples]</code>
Thus, we can:</p>
<p><div class="highlight"><pre><span></span><code><span class="c1"># Get first feature and all samples</span>
<span class="n">sp</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Or equivalently</span>
<span class="n">sp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Get first sample and all features</span>
<span class="n">sp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div>
Note that if you subset your <code>SummarizedPy</code>, it will be reflected in the <code>history</code> attribute:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Subset first feature and all samples</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h3 id="a-note-on-dimensionality">A note on dimensionality<a class="headerlink" href="#a-note-on-dimensionality" title="Permanent link">&para;</a></h3>
<p><code>SummarizedPy</code> enforces a 2D constraint on all three main attributes <code>data features samples</code>
such that you always get a 2D <code>numpy</code> array when calling <code>sp.data</code> and a full <code>pandas</code>
DataFrame when calling <code>sp.features</code> or <code>sp.samples</code></p>
<p><strong>Critically</strong>, <code>SummarizedPy</code> enforces the following rules:</p>
<p><div class="highlight"><pre><span></span><code><span class="n">sp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">sp</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">sp</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
Indeed, if you were to try
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;feature_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;feature1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature3&quot;</span><span class="p">]})</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sample1&quot;</span><span class="p">,</span> <span class="s2">&quot;sample2&quot;</span><span class="p">]})</span>

<span class="n">sp</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">SummarizedPy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>
</code></pre></div>
You would get a <code>ValueError</code> saying <code>Number of samples (2) does not match number of columns in data (3)</code></p>
<p>This is because <code>SummarizedPy</code> maps <code>samples</code> and <code>features</code> to <code>data</code>by indexing.
Thus, order of rows in these attributes is <strong>the</strong> source of truth.</p>
<p>As a consequence, re-assigning <code>data</code> is not possible and will raise an <code>AttributeError</code></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;feature_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;feature1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature2&quot;</span><span class="p">,</span> <span class="s2">&quot;feature3&quot;</span><span class="p">]})</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sample1&quot;</span><span class="p">,</span> <span class="s2">&quot;sample2&quot;</span><span class="p">,</span> <span class="s2">&quot;sample3&quot;</span><span class="p">]})</span>

<span class="n">sp</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">SummarizedPy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>

<span class="c1"># Trying to re-assign .data will raise AttributeError</span>
<span class="n">sp</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
</code></pre></div>
<p>Similarly, you will not be able to re-assign <code>.history</code> or <code>.results</code> (we will see this one later)</p>
<p>You <strong>can</strong> however mutate in-place, but this will <strong>not</strong> be reflected in <code>history</code>
and should therefore be done at your own peril. We like audit trails, right?
<div class="highlight"><pre><span></span><code><span class="c1"># Mutate in-place possible but not recommended</span>
<span class="n">sp</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></p>
<h2 id="filtering-by-sample-and-feature-metadata">Filtering by sample and feature metadata<a class="headerlink" href="#filtering-by-sample-and-feature-metadata" title="Permanent link">&para;</a></h2>
<p>We can filter the entire <code>SummarizedPy</code> object based on variables in the <code>.features</code> and <code>.samples</code> attributes.
This is easily done using the <code>filter_features</code> and <code>filter_samples</code> methods, resp.
These functions take a <code>pandas query()</code> style expression or a boolean mask.
Returning to our <code>load_example_data</code> example, we can filter based on sample, metadata:</p>
<p><div class="highlight"><pre><span></span><code><span class="c1"># Filtering samples</span>
<span class="c1"># Include sample condition variable (first six = ADC; last six = SCC)</span>
<span class="n">sp</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;condition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ADC&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;SCC&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span>

<span class="c1"># Filter for SCC samples using pandas query expression</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_samples</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="s2">&quot;condition==&#39;SCC&#39;&quot;</span><span class="p">)</span>

<span class="c1"># Check dimensions</span>
<span class="n">sp</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
Similarly, we can filter based on feature metadata:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Filtering features</span>
<span class="c1"># Create boolean vector indicating reverse hits</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="n">rev_hits</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;protein_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s2">&quot;REV&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)))</span>

<span class="c1"># Add as feature metadata</span>
<span class="n">sp</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;rev&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rev_hits</span>

<span class="c1"># Filter out reverse hits using pandas query expression</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_features</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="s2">&quot;~rev&quot;</span><span class="p">)</span>

<span class="c1"># Alternatively, use a boolean mask</span>
<span class="n">sp</span><span class="o">.</span><span class="n">filter_features</span><span class="p">(</span><span class="n">mask</span><span class="o">=~</span><span class="n">rev_hits</span><span class="p">)</span>

<span class="c1"># Check dimensions</span>
<span class="n">sp</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="missingness-filtering">Missingness filtering<a class="headerlink" href="#missingness-filtering" title="Permanent link">&para;</a></h2>
<p>In MS-based -omics, missing data is a guarantee. Whether you have DDA or DIA, there will NA (or nan) values.
When conducting differential expression analyses, you need sufficient valid values to base your fold changes on.
It makes no sense trying to compute a fold change if one group has 90% missing values for some feature (at least not with linear models).
We will not go into all the reasons for missingness, when it is and when it is not a problem;
rather, we will simply assume that we want some ceiling on missingness.</p>
<p>In Perseus (and proteomics more generally), the standard approaches to missingness filtering include:
- % valid values across <strong>all</strong> samples
- % valid values in <strong>at least one</strong> experimental condition
- % valid values in <strong>every experimental condition</strong></p>
<p>DEPy caters to all three and lets you set the threshold, expressed as the fraction of valid (i.e. non-nan) values.
Simply set the <code>strategy=</code> to one of
- <code>overall</code> (across all samples)
- <code>any_condition</code> (at least one condition)
- <code>all_conditions</code> (each condition)</p>
<p>Note that if you use one of the condition-based methods,
you need to set the <code>condition_column</code> parameter to indicate the name of the column in <code>samples</code> to filter on.</p>
<p>Finally, set the <code>frac</code> parameter to the fraction of minimum valid values required (default to 0.75; i.e. $\ge$75% valid value).</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Confirm the presence of nan values</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="c1"># Missingness filtering method</span>
<span class="c1"># Across all samples (i.e. independent of condition)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_missingness</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;overall&quot;</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="c1"># At least one condition (i.e. as a fraction of either SCC or ADC)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_missingness</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;any_condition&quot;</span><span class="p">,</span>
                      <span class="n">condition_column</span><span class="o">=</span><span class="s2">&quot;condition&quot;</span><span class="p">,</span>
                      <span class="n">frac</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="c1"># In each condition (i.e. as a fraction of both SCC and ADC)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_missingness</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;all_conditions&quot;</span><span class="p">,</span>
                      <span class="n">condition_column</span><span class="o">=</span><span class="s2">&quot;condition&quot;</span><span class="p">,</span>
                      <span class="n">frac</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="c1"># Check dimensions</span>
<span class="n">sp</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="highly-variable-feature-selection">Highly variable feature selection<a class="headerlink" href="#highly-variable-feature-selection" title="Permanent link">&para;</a></h2>
<p>Sometimes, you have too many features to analyze. This can reduce your power in DEA due to the multiple comparisons problem.
In machine learning, you may want to start building a regularized model with a smaller subset of features so as not to waste computational time on
low-variance features.</p>
<p>DEPy has a built-in solution for this with its <code>select_variable_features</code> method.
When selecting high-variance features, it is important to account for the heteroscedasticity in the data.
Otherwise, we would end up biasing our selection, as the underlying feature variance increases as a function of the average intensity.</p>
<p>Similar to the approach taken by <code>Seurat</code>, DEPy models the mean-variance trend of the data by fitting a LOWESS model to the feature-wise means and standard deviations.
Note that this calculation will be done on log transformed data. DEPy detects whether a log transformation has been done previously
based on the object's <code>history</code> attribute and runs one if not (the data will be returned un-transformed).
It then computes standardized residuals (i.e. the deviation from the fitted dispersion values) and ranks the features based on these z-scores.</p>
<p>You can then choose to return either the <code>top_n</code> (e.g. top 100) or <code>top_percentile</code> (e.g. top 5th percentile) of variable features.
Additionally, the method can display a plot of the data's mean-variance relationship, the fitted LOWESS trend, and highly variable features (HVF) labeled.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Return the top 100 most variable features and show mean-variance trend plot</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">select_variable_features</span><span class="p">(</span><span class="n">top_n</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Return the top 5% most variable features (calculated as 100-top_percentile)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">select_variable_features</span><span class="p">(</span><span class="n">top_percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="transformations">Transformations<a class="headerlink" href="#transformations" title="Permanent link">&para;</a></h2>
<p>There are several common data transformations and normalizations procedures in proteomics and metabolomics,
each of which can be performed in a sample- or feature-wise manner.
- <strong>log transformation</strong> (partly addresses the inherent heteroscedasticity in intensity data)
- <strong>centering</strong> (subtracting a constant such as mean or median to remove offset differences)
- <strong>standardization</strong> (aka z-scoring; enforces unit variance and symmetry about the mean, i.e. 0)</p>
<p>Another powerful transformation that addresses both heteroscedasticity and can reduce intra-group variance is the
<em>variance stabilizing normalization</em>, popularized by the R package <code>vsn</code>.
In short, it uses a generalized logarithm with a linear transformation to remove the asymptote at 0 that otherwise occurs with the standard log transform.
The affine (linear) transformation performs a column-wise centering and scaling with parameters estimated empirically.
This method, initially introduced for microarray studies, has its roots in error models developed for gas chromatography.
Check out the original <a href="https://pubmed.ncbi.nlm.nih.gov/12169536/">paper</a> by Wolfgang Huber et al.
I personally use this a lot for untargeted metabolomics and with other tools such as <a href="https://biofam.github.io/MOFA2/">MOFA</a>.</p>
<p>While many more transformations exist, the three listed ones are arguably the most common in proteomics.
DEPy gives you the ability to perform each one in a column- or row-wise manner using the <code>transform_features</code> method.
It uses numpy to make them blazingly fast where possible, and calls R for vsn.</p>
<p>The three main parameters are:
- method: one of <code>'log'</code>, <code>'center'</code>, <code>'z-score'</code>, <code>'vsn'</code>
- by: one of <code>'mean'</code> or <code>'median'</code> for <code>method='center'</code> or an <code>int</code> for <code>method='log'</code>
- axis: <code>0</code> for row-wise (feature-wise),  <code>1</code> column-wise (sample-wise) (omitted for methods <code>log</code> and <code>vsn</code>)</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Log transformation (base 2)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">transform_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Center data sample-wise by median</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">transform_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Feature-wise standardization</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">transform_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;z-score&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># vsn normalization</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">transform_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;vsn&quot;</span><span class="p">)</span>

<span class="c1"># Check data</span>
<span class="n">sp</span><span class="o">.</span><span class="n">data</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="imputation">Imputation<a class="headerlink" href="#imputation" title="Permanent link">&para;</a></h2>
<p>Depending on whom you ask, this is either a valid or questionable idea. We will not debate it here.
I would simply note (based on having conducted systematic trials) that you should <strong>only</strong> impute provided you have a sufficient number of valid values to base the imputation on.
What constitutes <em>sufficient</em> is like asking 'how long is a piece of string', but if I <em>had to</em> pick a number, I would say $\ge$50% valid values per condition <em>at a minimum</em>.</p>
<p>For our purposes here, missingness comes in two flavors:
- MAR (missing at random): the missingness pattern is randomly distributed and independent of the features
- MNAR (missing <em>not</em> at random): usually left-censored data in MS-based -omics, whereby features are missing due to low abundance.</p>
<p>DEPy runs the ImputeLCMD R package under the hood. This is a great package, created by Cosmin Lazar et al.
It comes with methods for MAR, MNAR, and <em>critically</em>, hybrid MAR-MNAR assumptions.
Which assumption to use is beyond the scope of this tutorial, but check out Lazar's excellent <a href="https://pubmed.ncbi.nlm.nih.gov/26906401/">paper</a> on the topic.</p>
<p>Accordingly, DEPy comes with all of those methods and supports all native parameters.
Exploring them all is a bit much, so we will only demonstrate the <code>hybrid</code> method.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Filter excessive missinginess</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_missingness</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;overall&quot;</span><span class="p">)</span>

<span class="c1"># Impute remaining missing values with hybrid approach</span>
<span class="c1"># MAR = KNN (default)</span>
<span class="c1"># MNAR = QRILC (default)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">impute_missing_values</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;Hybrid&quot;</span><span class="p">,</span> <span class="n">extra_args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;mar&quot;</span><span class="p">:</span> <span class="s2">&quot;KNN&quot;</span><span class="p">,</span> <span class="s2">&quot;mnar&quot;</span><span class="p">:</span> <span class="s2">&quot;QRILC&quot;</span><span class="p">})</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="surrogate-variable-analysis">Surrogate variable analysis<a class="headerlink" href="#surrogate-variable-analysis" title="Permanent link">&para;</a></h2>
<p>This is an <strong>excellent</strong> tool for any bioinformatician to have in their toolbox. Indeed, it has proven invaluable in some of my own work,
which deals with real-world, messy data from humans and animals. The method is surprisingly intuitive for all its seeming complexity.
Check out the original <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC1994707/">paper</a> by Leek et al.; it is a fantastic read.</p>
<h3 id="why-use-sva">Why use sva<a class="headerlink" href="#why-use-sva" title="Permanent link">&para;</a></h3>
<p>Sometimes, we have known batch effects or technical covariates that can be readily included in our models as adjustment variables.
However, sometimes, there can be <em>hidden</em> batch effects in your data that manifest as latent noise and correlations among features that we cannot account for.
How do you include something you cannot measure?</p>
<h3 id="this-is-why-sva">This is why sva<a class="headerlink" href="#this-is-why-sva" title="Permanent link">&para;</a></h3>
<p>In a nutshell, surrogate variable analysis (sva) performs PCA on the residuals of the data matrix after regressing out a fully parametrized models
that includes all known experimental and technical covariates. Then, it uses the resultant factors to capture latent covariation among features,
check which features associates with the factors, computes a new model on the reduced set, and returns the latent factors (aka "surrogate variables"),
which can be included as technical covariates in your subsequent model.</p>
<p><em>neat...</em></p>
<p>DEPy runs the <code>sva</code> R package with all its native arguments.
Simply specify your fully parametrized model, including all variables of interest (both experimental ones you care about, and adjustment/technical/batch variables).
Additionally, <code>sva</code> requires a so-called null model that includes only <em>known</em> adjustment variables. If you do not have any known ones, the default is to simply use an intercept model.
Note that you must specify the models with R-style tilde expressions; e.g. <code>~var1+var2</code></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Filter excessive missinginess (this is important)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">filter_missingness</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;overall&quot;</span><span class="p">)</span>

<span class="c1"># Log transform data (important)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">transform_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Optionally, impute missing remaining values (sva excludes any feature with nan values)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">impute_missing_values</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;Hybrid&quot;</span><span class="p">)</span>

<span class="c1"># Run sva</span>
<span class="c1"># Default null model: mod0 = &#39;~1&#39; (intercept-only)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">surrogate_variable_analysis</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s2">&quot;~condition&quot;</span><span class="p">)</span>

<span class="c1"># Surrogate variables are added to samples attribute</span>
<span class="n">sp</span><span class="o">.</span><span class="n">samples</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="limma-trend">limma-trend<a class="headerlink" href="#limma-trend" title="Permanent link">&para;</a></h2>
<p>Now for the actual differential expression analysis, we will use limma, brain child of Gordon Smyth
(check out the legendary <a href="https://pubmed.ncbi.nlm.nih.gov/16646809/">paper</a>).
Limma leverages an empirically estimated mean-variance trend as a prior to adjust for the heteroscedasticity common to so many -omics modalities.
This Bayesian prior serves as a form shrinkage, which mitigates the inflated false positive and negative rates
that come with conducting fold change analysis on low- and high-abundant features if the mean-variance is not accounted for.
This is particularly useful for small sample sizes.
Limma-trend was implemented and adapted in the proteomics R packages <code>DEqMS</code> and <code>DEP</code> for these very reasons.
Limma has been found to be more powerful and exert better FDR control than standard parametric statistics (i.e. t-test and ANOVA).
Critically, <code>limma-trend</code> performs about as well when adjusting for the mean-variance trend using the feature-wise intensity distribution as
when using peptide or PSM counts to adjust protein-level variance (see DEqMS <a href="https://pubmed.ncbi.nlm.nih.gov/32205417/">paper</a>).</p>
<p>Another massive benefit to limma is that it can incorporate sample quality weights calculated by its <code>arrayWeights</code> function.
In my years, I have found that it makes all the difference when working with data from human and animal samples.
In short, the weights are calculated by allowing each feature to have a sample-specific source of variation.
Using the overall mean-variance trend of the dataset, each sample can be quantified in terms of how much it deviates from the average (i.e. how 'noisy' a sample is).
This information is then incorporated into the weights, which are reciprocal logarithms of that deviation
(e.g. a quality weight of 0.5 is 2x as variable as the average sample; i.e. likely low quality).
The weights take the experimental design into account and can be estimated for each sample or averaged as a function of some covariate
(e.g. if quality was found to be reliably lower due to variable).</p>
<p>Finally, limma is highly flexible due to being a linear model. it can incorporate mixed effects, repeated measures, and between- and within-subjects factors.</p>
<p>Limma is available with most of its native parameters. Simply specify the design, the contrasts, whether to include array weights, etc.
- <code>design_formula</code> (R-style tilde expression with covariates of interest)
- <code>contrasts</code> (dictionary with the names and definitions of contrasts)
- <code>array_weights</code> (boolean; whether to include sample quality weights)</p>
<h4 id="a-brief-note-on-design-formulae">A brief note on design formulae<a class="headerlink" href="#a-brief-note-on-design-formulae" title="Permanent link">&para;</a></h4>
<p>DEPy will automatically enforce a marginal means model; that is, an intercept will <strong>not</strong> be included even if you specify one.
This is to keep the design matrix tidy to ensure proper matching between its column names and contrast terms.
To this end, DEPy will:
- inject a '~' if you forget one
- add a '0+' to the start of the <code>design_formula</code></p>
<p>In general, the intercept term is often of little interest (it represents the grand average) and will not affect fold changes.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Specify design formula (including &#39;condition&#39; and surrogate variables)</span>
<span class="n">des</span> <span class="o">=</span> <span class="s2">&quot;~condition+sv_1+sv_2+sv_3&quot;</span>

<span class="c1"># Define contrast (levels must be present in covariates above)</span>
<span class="n">contr</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;SCCvsADC&quot;</span><span class="p">:</span> <span class="s2">&quot;SCC-ADC&quot;</span><span class="p">}</span>

<span class="c1"># Run limma-trend with array_weights option</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">limma_trend_dea</span><span class="p">(</span><span class="n">design_formula</span><span class="o">=</span><span class="n">des</span><span class="p">,</span> <span class="n">contrasts</span><span class="o">=</span><span class="n">contr</span><span class="p">,</span> <span class="n">array_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Check newly created results attribute</span>
<span class="n">sp</span><span class="o">.</span><span class="n">results</span>

<span class="c1"># Check history</span>
<span class="n">sp</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>
<h2 id="volcano-plots">Volcano plots<a class="headerlink" href="#volcano-plots" title="Permanent link">&para;</a></h2>
<p>Finally, we will plot the estimate log fold changes against the log-transformed nominal p-values per feature for each contrast.
<em>Better known as a volcano plot.</em>
This is very simple in DEPy: you can either provide a list contrast names or let DEPy produce one volcano plot per contrast.
Plots are generated with <code>matplotlib</code> and returned as a tuple of dictionaries with keys = contrast names
and values = <code>matplotlib.Figure</code> or <code>matplotlib.Axes</code> objects.</p>
<p><div class="highlight"><pre><span></span><code><span class="c1"># Generate volcano plots for all contrasts</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">volcano_plot</span><span class="p">()</span>

<span class="c1"># Optionally, specify the name of a contrast</span>
<span class="n">sp</span><span class="o">.</span><span class="n">volcano_plot</span><span class="p">(</span><span class="n">contrasts</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;SCCvsADC&quot;</span><span class="p">])</span>
</code></pre></div>
By default, the function plots the top 3 up- and top 3 down-regulated features according to FDR.
This can be changed with the <code>top_n</code> parameter.
You can also change color scheme by providing a dictionary with names <code>'Up'</code>, <code>'Down'</code>, and <code>'ns'</code>,
and hexcodes or valid color names as values.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Highlight top up- and down-regulated features</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">volcano_plot</span><span class="p">(</span><span class="n">top_n</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Change colors</span>
<span class="n">de_colors</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Up&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;Down&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;ns&quot;</span><span class="p">:</span> <span class="s2">&quot;white&quot;</span><span class="p">}</span>
<span class="n">sp</span><span class="o">.</span><span class="n">volcano_plot</span><span class="p">(</span><span class="n">de_colors</span><span class="o">=</span><span class="n">de_colors</span><span class="p">)</span>
</code></pre></div>
<h2 id="pca-plots">PCA plots<a class="headerlink" href="#pca-plots" title="Permanent link">&para;</a></h2>
<p>It is common to visualize your data with PCA to get an idea of what the variance structure is like.
This is particularly useful in combination with labeling and coloring according to some condition or variable to reveal clustering or outlier samples.
DEPy has a simple plotting function for this, which calls scikit-learn's PCA estimator under the hood with all defaults (standard SVD).
It is important to remember that PCA is highly sensitive to feature scale and range, such that if some features have greater range,
the model will return components that mainly reflect the differences in feature scales. This is commonly remedied by standardizing the features (i.e. z-scoring) first.
This can be done by calling the <code>plot_pca</code> method with <code>standardize=True</code>.</p>
<p>The method both displays the PCA plot and returns <code>matplotlib.Figure</code> or <code>matplotlib.Axes</code> objects as a tuple.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Plot PCA with example dataset using method defaults</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot_pca</span><span class="p">()</span>
</code></pre></div>
<p>You can change the number of principal components to estimate using the <code>n_comp</code> argument.
However, the method only plots samples along the first two components.</p>
<p>To color samples by some condition or variable, simply provide a valid string to the <code>fill_by</code>argument indicating a column in the <code>samples</code> attribute.
To label individual sample points, set <code>label=True</code>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Plot PCA and color by tumor condition and label individual samples</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot_pca</span><span class="p">(</span><span class="n">fill_by</span><span class="o">=</span><span class="s2">&quot;condition&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>There you have it!</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../installation/" class="btn btn-neutral float-left" title="Installation"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../api/" class="btn btn-neutral float-right" title="API Reference">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/SebastianDHA/DEPy" class="fa fa-code-fork" style="color: #fcfcfc"> SebastianDHA/DEPy</a>
        </span>
    
    
      <span><a href="../installation/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../api/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
